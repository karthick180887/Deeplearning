{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS6nXE_pOA0g",
        "outputId": "2419454e-8d51-44d7-a705-0c96e54c0e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Human-Segmentation-Dataset'...\n",
            "remote: Enumerating objects: 596, done.\u001b[K\n",
            "remote: Total 596 (delta 0), reused 0 (delta 0), pack-reused 596 (from 1)\u001b[K\n",
            "Receiving objects: 100% (596/596), 13.60 MiB | 39.23 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/VikramShenoy97/Human-Segmentation-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import Adam, AdamW, SGD"
      ],
      "metadata": {
        "id": "iiVgfWQLODLK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "  def __init__(self, image_dir, mask_dir):\n",
        "    self.image_dir = image_dir\n",
        "    self.mask_dir = mask_dir\n",
        "    self.transform = transforms.Compose([\n",
        "        transforms.Resize((512, 512)),\n",
        "        transforms.ToTensor()])\n",
        "\n",
        "    valid_extension = {\".jpg\", \".jpeg\", \".png\"}\n",
        "    self.images = [f for f in os.listdir(image_dir) if os.path.splitext(f)[1].lower() in valid_extension]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "    name, ext = os.path.splitext(self.images[idx])\n",
        "    mask_path = os.path.join(self.mask_dir, f\"{name}.png\")\n",
        "\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "    image = self.transform(image)\n",
        "    mask = self.transform(mask)\n",
        "\n",
        "    mask = (mask > 0.5).float()\n",
        "\n",
        "    return image, mask"
      ],
      "metadata": {
        "id": "uU3RmHN5OM0T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(image_dir, maks_dir, batch_size=2, shuffle=True):\n",
        "  dataset = SegmentationDataset(image_dir, maks_dir)\n",
        "  return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
      ],
      "metadata": {
        "id": "2V9xHh3tOVp6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv_op = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3,padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3,padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv_op(x)"
      ],
      "metadata": {
        "id": "5uuawkkfOZL7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "      super().__init__()\n",
        "      self.conv = DoubleConv(in_channels, out_channels)\n",
        "      self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "      down = self.conv(x)\n",
        "      p = self.pool(down)\n",
        "\n",
        "      return down, p"
      ],
      "metadata": {
        "id": "jPexvol4Ob02"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "       x1 = self.up(x1)\n",
        "       x = torch.cat([x1, x2], 1)\n",
        "       return self.conv(x)"
      ],
      "metadata": {
        "id": "ysEA9XI2Oe7z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.down_convolution_1 = DownSample(in_channels, 64)\n",
        "        self.down_convolution_2 = DownSample(64, 128)\n",
        "        self.down_convolution_3 = DownSample(128, 256)\n",
        "        self.down_convolution_4 = DownSample(256, 512)\n",
        "\n",
        "        self.bottle_neck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up_convolution_1 = UpSample(1024, 512)\n",
        "        self.up_convolution_2 = UpSample(512, 256)\n",
        "        self.up_convolution_3 = UpSample(256, 128)\n",
        "        self.up_convolution_4 = UpSample(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "       down_1, p1 = self.down_convolution_1(x)\n",
        "       down_2, p2 = self.down_convolution_2(p1)\n",
        "       down_3, p3 = self.down_convolution_3(p2)\n",
        "       down_4, p4 = self.down_convolution_4(p3)\n",
        "\n",
        "       b = self.bottle_neck(p4)\n",
        "\n",
        "       up_1 = self.up_convolution_1(b, down_4)\n",
        "       up_2 = self.up_convolution_2(up_1, down_3)\n",
        "       up_3 = self.up_convolution_3(up_2, down_2)\n",
        "       up_4 = self.up_convolution_4(up_3, down_1)\n",
        "\n",
        "       out = self.out(up_4)\n",
        "       return out"
      ],
      "metadata": {
        "id": "azqPDFDhOiyI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "  def __init__(self, smooth=1e-6):\n",
        "    super(DiceLoss, self).__init__()\n",
        "    self.smooth = smooth\n",
        "\n",
        "  def forward(self, inputs, targets):\n",
        "    inputs = inputs.view(-1)\n",
        "    targets = targets.view(-1)\n",
        "\n",
        "    intersection = (inputs * targets).sum()\n",
        "    dice_score = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
        "\n",
        "    return 1 - dice_score"
      ],
      "metadata": {
        "id": "5OxuWoVpOlWr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BCEWithDiceLoss(nn.Module):\n",
        "  def __init__(self, smooth=1e-6):\n",
        "    super(BCEWithDiceLoss, self).__init__()\n",
        "    self.bce = nn.BCEWithLogitsLoss()\n",
        "    self.dice = DiceLoss()\n",
        "\n",
        "  def forward(self, inputs,targets):\n",
        "    bce_loss = self.bce(inputs,targets)\n",
        "    dice_loss = self.dice(inputs,targets)\n",
        "    return 0.5*bce_loss + dice_loss"
      ],
      "metadata": {
        "id": "Pk_-vbmqOn57"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "\n",
        "def train(model, dataloader, epochs=2, lr=0.001, save_path=\"unet_model\", load_path=None):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  if load_path and os.path.exists(load_path):\n",
        "    print(f\"Loading model weights from {load_path}\")\n",
        "    model.load_state_dict(torch.load(load_path, map_loacation=device))\n",
        "  else:\n",
        "    print(f\"No checkpoint found, training from scratch.\")\n",
        "\n",
        "  print(device)\n",
        "  model.to(device)\n",
        "\n",
        "  criterion = BCEWithDiceLoss()\n",
        "  # criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  optimizer = SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for images, masks in dataloader:\n",
        "      images, masks = images.to(device), masks.to(device)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(images)\n",
        "\n",
        "      loss = criterion(output, masks)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss : {avg_loss:.4f}, LR : {lr}\")\n",
        "\n",
        "    if epoch % 10 == 0 and epoch>0:\n",
        "      torch.save(model.state_dict(), f\"{save_path}.pth\")\n",
        "\n",
        "  torch.save(model.state_dict(), f\"{save_path}_final.pth\")\n",
        "  print(f\"Model Saved to {save_path}\")\n"
      ],
      "metadata": {
        "id": "Cpv6MG9cOrtK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = get_dataloader(\"/content/Human-Segmentation-Dataset/Training_Images\", \"/content/Human-Segmentation-Dataset/Ground_Truth\", batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "vOXT6mplOuhU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(in_channels=3, num_classes=1)"
      ],
      "metadata": {
        "id": "mZOjxYa7O-4j"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, dataloader, epochs=2, lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaxrppRZPA_U",
        "outputId": "8bc521e2-3d5c-49cd-bbb0-273b2a1b2ad9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found, training from scratch.\n",
            "cuda\n",
            "Epoch [1/2], Loss : 1.3963, LR : 0.001\n",
            "Epoch [2/2], Loss : 1.2528, LR : 0.001\n",
            "Model Saved to unet_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load model and predict with stats\n",
        "def predict(model_path, input_image_path):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load model\n",
        "    model = UNet(in_channels=3, num_classes=1)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Track start time\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    # Image preprocessing\n",
        "    preprocess_start_time = time.time()\n",
        "    image = Image.open(input_image_path).convert(\"RGB\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((512, 512)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "    preprocess_end_time = time.time()\n",
        "\n",
        "    # Model inference\n",
        "    inference_start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        output = torch.sigmoid(output)\n",
        "    inference_end_time = time.time()\n",
        "\n",
        "    # Postprocessing\n",
        "    postprocess_start_time = time.time()\n",
        "    mask = output.squeeze(0).squeeze(0).cpu().numpy()\n",
        "    mask = (mask > 0.4).astype(np.uint8) * 255\n",
        "    mask_image = Image.fromarray(mask)\n",
        "\n",
        "    combined = Image.new(\"RGB\", (512 * 2, 512))\n",
        "    combined.paste(image.resize((512, 512)), (0, 0))\n",
        "    combined.paste(mask_image.convert(\"RGB\"), (512, 0))\n",
        "    combined.save(\"output.jpg\")\n",
        "    postprocess_end_time = time.time()\n",
        "\n",
        "    # Calculate timing stats\n",
        "    total_end_time = time.time()\n",
        "\n",
        "    preprocess_time = preprocess_end_time - preprocess_start_time\n",
        "    inference_time = inference_end_time - inference_start_time\n",
        "    postprocess_time = postprocess_end_time - postprocess_start_time\n",
        "    total_time = total_end_time - total_start_time\n",
        "\n",
        "    # Print stats\n",
        "    print(\"\\nPrediction completed! Stats:\")\n",
        "    print(f\"  Image Preprocessing Time: {preprocess_time:.4f} seconds\")\n",
        "    print(f\"  Model Inference Time: {inference_time:.4f} seconds\")\n",
        "    print(f\"  Postprocessing Time: {postprocess_time:.4f} seconds\")\n",
        "    print(f\"  Total Prediction Time: {total_time:.4f} seconds\")\n",
        "    print(\"Prediction saved as output.jpg\")\n"
      ],
      "metadata": {
        "id": "wF1PzVwEPC3V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model_path=\"/content/unet_model_final.pth\", input_image_path=\"/content/Human-Segmentation-Dataset/Training_Images/5.jpg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0KUwTxjPk2M",
        "outputId": "9e0213a5-4897-4f82-e5b2-d0faf4f1287a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Prediction completed! Stats:\n",
            "  Image Preprocessing Time: 0.0061 seconds\n",
            "  Model Inference Time: 0.0205 seconds\n",
            "  Postprocessing Time: 0.1023 seconds\n",
            "  Total Prediction Time: 0.1288 seconds\n",
            "Prediction saved as output.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2t5r8MlcQBZT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}